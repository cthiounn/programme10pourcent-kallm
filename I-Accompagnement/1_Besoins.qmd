# Guide du LLM

## PARTIE I. Accompagnement au changement

Partie à fusionner avec ce qui existe déjà dans l'administration ?
Partir des capacités des LLM pour ensuite les décliner en cas d'usage.
Parler de l'accès aux données (pour du RAG, FT...)
Parler de la nécessité d'avoir du GPU par rapport aux ambitions
Il faut avoir les moyens de ces ambitions 
Il faut avoir un cadre juridique cohérent avec ses besoins

### 1. Besoins (Johnny Hélène)

	Vision high level de l'intérêt des LLMs

Les cas d'usages des LLMs sont variés et avant de se lancer et innover grâce aux LLMs, il est nécessaire de bien identifier le besoin qui amène l'utilisation d'un LLM. Pour quoi faire ? Pour quels usages ? Est-ce pour de la génération de texte ? Pour de la classification ?
L'objectif de ce chapitre est d'accompagner la réflexion autour de l'identification du besoin et de la collecte des données, avec les différents types de cas d'usages impliquant des LLMs.
 
 Les cas d'usages :

 * cas d'usages autour de la génération de contenu
 * cas d'usage autour de la classification et de la recherche de contenu
 * cas d'usage autour des interactions conversationnelles

Partie à mettre dans une section dédiée ? Expliciter les motivations pour utiliser un SLM plutôt qu'un LLM / les questions à se poser avant d'utiliser un LLM
### Description cas d'usage

 1. Utilisation des SLM pour la recherche thématique simple en français (en cours, Zhanna)<br>
Malgré la disponibilité et l’attractivité des « grands » modèles langages comme GPT et Mixtral, l’utilisation des petits modèles classiques est parfois plus avantageuse, surtout quand les ressources techniques ou l’accès aux données sont restreints.\
C’est vrai dans le cas d’utilisation d’un SLM basé sur un modèle devenu classique, BERT qui donne la naissance à milliers de modèles spécialisés comme [CamemBERT](https://arxiv.org/abs/1911.03894) un modèle en français ou encore [sBERT ou sentenceTransformers](https://sbert.net/) permettant un entraînement spécialisé pour une recherche sémantique.
<br>
**ici plus d'information sur les avantages des SLM (données, environement, spécialisation, travail en local, technique)
<br>
Nous considérons un exemple d’utilisation de CamemBERT-base et un exemple de sBERT :

1. [camembert-bio-base](https://huggingface.co/almanach/camembert-bio-base) avec ses 111M de paramètres, pour une recherche thématique dans des textes scientifiques biomédicaux.
Nous utiliserons les transformers de [HuggingFace](https://github.com/huggingface/transformers)
```python
from transformers import AutoTokenizer, AutoModelForMaskedLM
biotokenizer = AutoTokenizer.from_pretrained("almanach/camembert-bio-base")
biomodel = AutoModelForMaskedLM.from_pretrained("almanach/camembert-bio-base")
```

2. [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
```python
import requests

api_url = f"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}"
headers = {"Authorization": f"Bearer {hf_token}"}
```


 2. Classifier des accords d'entreprise


#### Classifier des accords d'entreprise

Donner des informations sur les données : nombre de catégories, catégories hierarchiques ou pas, taille de la base...
 Les accords d'entreprise sont publiés sur [LégiFrance](https://www.legifrance.gouv.fr/liste/acco).
 Ces accords peuvent concerner plusieurs thématiques (télétravail, compte épargne temps, droit à la deconnexion).
 Ces thématiques sont déclarés par les entreprises et sont éventuellement corrigées par la Direction Générale du Travail.
 Le besoin est alors de détecter automatiquement les thématiques
 à la lecture de l'accord.
 Un jeu de données est disponible à l'adresse suivante : [accords_publics_xx_to_2022_themes_et_texte.parquet](https://minio.lab.sspcloud.fr/cthiounn2/Accords/accords_publics_xx_to_2022_themes_et_texte.parquet)
